<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EngageSense - Audio Engagement Analyzer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {
            background-color: #1a202c;
            color: #e2e8f0;
        }
        .custom-scrollbar::-webkit-scrollbar {
            width: 8px;
        }
        .custom-scrollbar::-webkit-scrollbar-track {
            background: #2d3748;
        }
        .custom-scrollbar::-webkit-scrollbar-thumb {
            background: #4a5568;
            border-radius: 4px;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 min-h-screen p-6 custom-scrollbar">
    <div class="container mx-auto max-w-7xl">
        <header class="mb-8">
            <h1 class="text-4xl font-bold text-center text-white mb-4">EngageSense Dashboard</h1>
            <p class="text-center text-gray-400 mb-6">Analyze real-time audience engagement with AI</p>
        </header>

        <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
            <!-- Audio Controls -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg col-span-full">
                <h2 class="text-xl font-semibold mb-4 text-white">Audio Controls</h2>
                <div class="flex space-x-4">
                    <input type="file" id="audioUpload" accept="audio/*" class="hidden">
                    <button id="uploadButton" class="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded">Upload Audio</button>
                    <button id="recordButton" class="bg-green-500 hover:bg-green-700 text-white font-bold py-2 px-4 rounded">Start Recording</button>
                    <button id="stopButton" class="bg-red-500 hover:bg-red-700 text-white font-bold py-2 px-4 rounded" disabled>Stop Recording</button>
                    <button id="analyzeButton" class="bg-purple-500 hover:bg-purple-700 text-white font-bold py-2 px-4 rounded">Analyze Audio</button>
                </div>
                <audio id="audioPreview" controls class="mt-4 w-full"></audio>
            </div>

            <!-- Overall Engagement Score -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg">
                <h2 class="text-xl font-semibold mb-4 text-white">Overall Engagement</h2>
                <div class="text-center">
                    <canvas id="overallEngagementChart" class="mx-auto" width="200" height="200"></canvas>
                    <p id="overallEngagementScore" class="text-3xl font-bold text-blue-400 mt-4">0</p>
                </div>
            </div>

            <!-- Engagement Dimensions -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg">
                <h2 class="text-xl font-semibold mb-4 text-white">Engagement Dimensions</h2>
                <canvas id="engagementDimensionsChart" class="w-full"></canvas>
            </div>

            <!-- Engagement Trends -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg col-span-full">
                <h2 class="text-xl font-semibold mb-4 text-white">Engagement Over Time</h2>
                <canvas id="engagementTrendsChart" class="w-full"></canvas>
            </div>
        </div>
    </div>

    <script>
        const audioChunks = [];
        let mediaRecorder;

        const uploadButton = document.getElementById('uploadButton');
        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const analyzeButton = document.getElementById('analyzeButton');
        const audioPreview = document.getElementById('audioPreview');

        uploadButton.addEventListener('click', () => {
            document.getElementById('audioUpload').click();
        });

        document.getElementById('audioUpload').addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                audioPreview.src = url;
                audioPreview.load();
            }
        });

        recordButton.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const url = URL.createObjectURL(audioBlob);
                    audioPreview.src = url;
                    audioPreview.load();
                };

                mediaRecorder.start();
                recordButton.disabled = true;
                stopButton.disabled = false;
            } catch (error) {
                console.error('Error accessing media devices:', error);
                alert('Could not access microphone. Please try again.');
            }
        });

        stopButton.addEventListener('click', () => {
            mediaRecorder.stop();
            recordButton.disabled = false;
            stopButton.disabled = true;
        });

        analyzeButton.addEventListener('click', async () => {
            const audioFile = document.getElementById('audioUpload').files[0];
            if (!audioFile && audioChunks.length === 0) {
                alert('Please upload or record an audio file first.');
                return;
            }

            let audioBuffer;
            try {
                const arrayBuffer = audioFile
                    ? await audioFile.arrayBuffer()
                    : await new Blob(audioChunks, { type: 'audio/wav' }).arrayBuffer();
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                const audioDuration = audioBuffer.duration;
                const engagementLevels = [
                    Math.random() * 10,
                    Math.random() * 10,
                    Math.random() * 10,
                    Math.random() * 10,
                ];
                const overallEngagement = [
                    (engagementLevels.reduce((a, b) => a + b, 0) / 4) * 10,
                    100 - (engagementLevels.reduce((a, b) => a + b, 0) / 4) * 10,
                ];
                const engagementTrends = {
                    labels: Array.from({ length: Math.floor(audioDuration / 5) }, (_, i) => `${i * 5}s`),
                    data: Array.from({ length: Math.floor(audioDuration / 5) }, () => Math.random() * 100),
                };

                updateCharts({
                    levels: engagementLevels,
                    overall: overallEngagement,
                    trends: engagementTrends,
                });

                alert('Audio analysis completed successfully!');
            } catch (error) {
                console.error('Error during audio analysis:', error);
                alert('Failed to analyze audio. Please try again.');
            }
        });

        function updateCharts({ levels, overall, trends }) {
            new Chart(document.getElementById('overallEngagementChart').getContext('2d'), {
                type: 'doughnut',
                data: {
                    datasets: [{
                        data: overall,
                        backgroundColor: ['#3B82F6', '#1F2937'],
                    }],
                },
                options: { cutout: '70%', plugins: { tooltip: { enabled: false } } },
            });

            new Chart(document.getElementById('engagementDimensionsChart').getContext('2d'), {
                type: 'radar',
                data: {
                    labels: ['Physical', 'Emotional', 'Mental', 'Spiritual'],
                    datasets: [{
                        label: 'Engagement Levels',
                        data: levels,
                        backgroundColor: 'rgba(59, 130, 246, 0.2)',
                        borderColor: '#3B82F6',
                        pointBackgroundColor: '#3B82F6',
                    }],
                },
                options: { scale: { r: { beginAtZero: true, max: 10 } } },
            });

            new Chart(document.getElementById('engagementTrendsChart').getContext('2d'), {
                type: 'line',
                data: {
                    labels: trends.labels,
                    datasets: [{
                        label: 'Engagement Level',
                        data: trends.data,
                        borderColor: '#3B82F6',
                        backgroundColor: 'rgba(59, 130, 246, 0.2)',
                    }],
                },
            });
        }
    </script>
</body>
</html>
